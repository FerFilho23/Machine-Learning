# ü§ñ Module 3 ‚Äî Machine Learning for Classification

This module introduces **classification modeling**, focusing on **Logistic Regression** for binary outcomes. The main hands-on project predicts **customer churn** using the **Telco Customer Churn** dataset from Kaggle.

## üéØ Learning Objectives
- Understand the difference between **regression** and **classification** problems  
- Explore **binary classification** using logistic regression  
- Apply **feature selection** (correlation, mutual information, risk ratio)  
- Implement **one-hot encoding** and data preprocessing   
- Train, interpret, and evaluate a logistic regression model using **Scikit-Learn**

## ‚öôÔ∏è Project: Churn Prediction

Notebook: [churn-prediction.ipynb](./churn-prediction.ipynb)

**Goal:** Classify customer churn for a telecom company.

### Steps:
1. **Data preprocessing**  
    
2. **Validation Framework**
   

3. **Exploratory Data Analysis (EDA)**


4. **Feature Selection**


5. **Encoding Categorical Variables**

6. **Logistic Regression Model**

7. **Model Interpretation**

7. **Model Evaluation**


## üí° Key Takeaways

- Logistic Regression models probability for binary outcomes using a sigmoid function.

- Data cleaning, encoding, and feature selection greatly impact performance.

- Mutual Information and correlation analysis help identify informative features.

- Evaluation metrics like ROC-AUC and Precision/Recall go beyond raw accuracy.

- Interpretable coefficients make logistic regression a powerful baseline model for classification.