# ğŸ“˜ Prompt Design on Google Cloud  

## ğŸ¯ Learning Objectives  
- Understand the **core principles of prompt design** for generative AI.  
- Learn the difference between **zero-shot**, **one-shot**, and **few-shot prompting**.  
- Explore **best practices** for writing clear, structured prompts.  
- Understand how **model parameters** such as **temperature**, **top-K**, and **top-P** control response randomness and creativity.  

---

## ğŸ“ Summary  

**Prompt design** is both an **art and a science**. Itâ€™s the process of crafting inputs that guide a generative AI model toward useful, accurate, or creative outputs. The way a prompt is written directly determines how the model interprets your request and what type of response it produces.  

In **Vertex AI Studio**, you can experiment with prompts in both **free-form** and **structured** modes, exploring how small adjustments affect model behavior.  

---

## ğŸ’¬ Prompting Methods  

There are **three main prompting strategies** for shaping model behavior:  

| **Method** | **Description** | **Example** |
|-------------|----------------|--------------|
| **Zero-Shot Prompting** | You provide an **instruction** with no examples. The model uses general knowledge to respond. | â€œGenerate a list of items I need for a camping trip to Joshua Tree National Park.â€ |
| **One-Shot Prompting** | You give the model **one example** to demonstrate the desired behavior. | â€œHereâ€™s a poem example â†’ Now write a similar poem about the ocean.â€ |
| **Few-Shot Prompting** | You include **multiple examples** of input-output pairs to guide the modelâ€™s style and logic. | IT Help Desk context with several Q&A examples before asking a new question. |

Few-shot prompting is especially powerful when you want the model to **imitate patterns** or **adhere to a tone or style**, such as customer support, data extraction, or storytelling.  

---

## ğŸ§± Structured Prompts  

A **structured prompt** combines several components:  

| **Component** | **Purpose** | **Example** |
|----------------|-------------|--------------|
| **Context** | Guides how the model should behave and respond. | â€œYou are an environmental researcher answering questions about rainforest vegetation.â€ |
| **Examples** | Shows model how to respond using prior question-answer pairs. | â€œQ: What does LGM stand for? â†’ A: Last Glacial Maximum.â€ |
| **Input** | The new query you want the model to answer. | â€œQ: What did the analysis from the sediment deposits indicate?â€ |

By combining context, examples, and input, you can quickly **prototype a Q&A system** or **simulate domain expertise** within minutes.  

---

## âœ… Best Practices for Effective Prompts  

- **Be concise and specific.** Clearly define the task or question.  
- **Ask one task at a time.** Avoid overloading the prompt with unrelated requests.  
- **Use examples.** Demonstrating the desired output improves consistency.  
- **Experiment.** Different formats and phrasings can yield different results, thereâ€™s no single â€œbestâ€ prompt.  

If a prompt produces strong results, you can **save it** in **Vertex AI Studioâ€™s Prompt Gallery**, a curated library of reusable and shareable prompts across use cases.  

---

## âš™ï¸ Model Parameters for Fine-Tuning Responses  

Beyond prompt wording, **Vertex AI Studio** provides several model parameters that affect the **randomness**, **creativity**, and **focus** of responses.  

### ğŸ”¹ 1. Temperature  
Controls **how deterministic or creative** the modelâ€™s responses are.  
- **Low (0â€“0.3):** Predictable and focused â€” best for Q&A or summarization tasks.  
- **High (0.7â€“1.0):** Diverse and imaginative â€” better for brainstorming, storytelling, or marketing copy.  

### ğŸ”¹ 2. Top-K Sampling  
Limits the next token (word) choices to the **K most probable options**, then randomly picks one.  
- Example: **Top-2** â†’ randomly selects between the two most likely next words.  
- Too small a K may cause repetitive answers; too large may introduce incoherence.  

### ğŸ”¹ 3. Top-P (Nucleus) Sampling  
Selects from the **smallest subset of words** whose cumulative probability â‰¥ **P**.  
- Example: **P = 0.75** â†’ sample from words that collectively make up 75% of likelihood.  
- Dynamic approach â€” adapts to the modelâ€™s probability distribution for smoother, natural variation.  

### ğŸ”¹ 4. Model Selection  
Each model is tuned for specific domains (e.g., text, multimodal, chat).  
Choose the one that best matches your use case before sending the prompt.  

> âš ï¸ You donâ€™t need to constantly tweak all parameters â€” **temperature** alone often provides sufficient control for most prompt-testing scenarios.  

---

## ğŸ’¡ Key Insights  

- **Prompt design** determines how effectively you can harness a GenAI modelâ€™s intelligence.  
- Use **zero-shot** for quick tasks, **one-shot** for stylistic control, and **few-shot** for complex behavior modeling.  
- Structured prompts (context + examples + input) enable consistent and domain-specific performance.  
- Experimentation is essential, refine prompts iteratively based on output quality.  
- Parameters like **temperature**, **top-K**, and **top-P** let you balance between precision and creativity.  
- Saved prompts in **Prompt Gallery** help you build reusable GenAI assets for future projects.  

---

## ğŸ“š References  
- [Content generation parameters](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters)  
- [Vertex AI Studio Prompt Gallery](https://cloud.google.com/vertex-ai/docs/generative-ai/prompt-gallery)  
